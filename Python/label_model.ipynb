{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "68cbed68-a297-4aa9-917d-eba8afee6e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d7539114-d478-4605-8fb3-ad166636356c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted API key: AIzaSyDUI59SBo58ubrKL6sQzBJo8phEoMfBG4U\n"
     ]
    }
   ],
   "source": [
    "# Read the content of the text file\n",
    "with open('project_important_info.txt', 'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "# Define a variable to hold the API key\n",
    "api_key = None\n",
    "\n",
    "# Loop through each line to find the API key\n",
    "for line in lines:\n",
    "    if \"Google map API key:\" in line:\n",
    "        # Extract the API key from the line\n",
    "        api_key = line.split(': ')[1].strip()\n",
    "\n",
    "# Print the extracted API key\n",
    "print(\"Extracted API key:\", api_key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "3c6e7fa7-402d-479b-b8f6-dd9d475eaab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gaudy', 'flash', 'brassy', 'garish', 'meretricious', 'aloud', 'loud', 'trashy', 'noisy', 'loudly', 'tacky', 'forte', 'flashy', 'gimcrack', 'cheap', 'tawdry', 'tatty'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/hanzhitan/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/hanzhitan/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "def merge_sets(sets):\n",
    "    merged_set = set()\n",
    "    for s in sets:\n",
    "        merged_set |= s\n",
    "    return merged_set\n",
    "    \n",
    "def get_synonyms(word):\n",
    "    synonyms = set()\n",
    "    for syn in wn.synsets(word):\n",
    "        for lemma in syn.lemmas():\n",
    "            synonyms.add(lemma.name().replace('_', ' '))\n",
    "    synonyms.add(word)\n",
    "    return synonyms\n",
    "def get_merge_syns(*words):\n",
    "    syn_lst = []\n",
    "    for w in words:\n",
    "        syn_lst.append(get_synonyms(w))\n",
    "    return merge_sets(syn_lst)\n",
    "    \n",
    "# Example synonyms for 'quiet'\n",
    "quiet_synonyms = get_merge_syns('noisy', 'loud')\n",
    "print(quiet_synonyms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b47991f6-ddb9-4d32-a46e-57a5a8c2a29f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "20\n",
      "40\n"
     ]
    }
   ],
   "source": [
    "def fetch_place_details(place_id, api_key):\n",
    "    details_url = f\"https://maps.googleapis.com/maps/api/place/details/json?place_id={place_id}&fields=reviews&key={api_key}\"\n",
    "    response = requests.get(details_url)\n",
    "    if response.status_code == 200:\n",
    "        return response.json().get('result', {}).get('reviews', [])\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "def fetch_places_nearby(api_key, location, radius, place_type):\n",
    "    url = \"https://maps.googleapis.com/maps/api/place/nearbysearch/json\"\n",
    "    params = {\n",
    "        'key': api_key,\n",
    "        'location': location,  # \"latitude,longitude\"\n",
    "        'radius': radius,\n",
    "        'type': place_type\n",
    "    }\n",
    "    response = requests.get(url, params=params)\n",
    "    results = response.json().get('results', [])\n",
    "    print(len(results))\n",
    "    \n",
    "    places = []\n",
    "    for place in results:\n",
    "        place_id = place.get(\"place_id\") \n",
    "        reviews = fetch_place_details(place_id, api_key)\n",
    "        places.append({\n",
    "            'name': place.get('name'),\n",
    "            'address': place.get('vicinity'),\n",
    "            'type': place_type,\n",
    "            'rating': place.get('rating', None),\n",
    "            'user_ratings_total': place.get('user_ratings_total', 0),\n",
    "            'latitude': place['geometry']['location']['lat'],\n",
    "            'longitude': place['geometry']['location']['lng'],\n",
    "            'reviews': reviews,\n",
    "        })\n",
    "    return places\n",
    "\n",
    "def fetch_all_places(api_key, location, radius, place_types):\n",
    "    all_places = []\n",
    "    for place_type in place_types:\n",
    "        places = fetch_places_nearby(api_key, location, radius, place_type)\n",
    "        all_places.extend(places)\n",
    "    return all_places\n",
    "\n",
    "# Define the boundaries of Chicago\n",
    "chicago_boundaries = [\n",
    "    (41.644335, -87.940267),  # South West corner\n",
    "    (42.023015, -87.523660)   # North East corner\n",
    "]\n",
    "\n",
    "# Set the radius and place types you want to fetch\n",
    "radius = 1000  # 10 km radius\n",
    "place_types = ['cafe', 'library']  # Add more types if needed\n",
    "\n",
    "# Fetch all places within the boundaries of Chicago\n",
    "all_places_chicago = fetch_all_places(api_key, '41.8781,-87.6298', radius, place_types)\n",
    "print(len(all_places_chicago))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "f4b909e1-a321-45f4-8abc-bfea7b13f3f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'quiet': {'hush', 'restrained', 'tranquillity', 'smooth', 'quiet down', 'muted', 'mute', 'quiet', 'private', 'hushed', 'secret', 'mum', 'soundless', 'tranquillize', 'quieten', 'self study', 'tranquil', 'silent', 'buck private', 'tranquility', 'dumb', 'calm', 'silence', 'individual', 'placid', 'calm down', 'tacit', 'tranquilize', 'pipe down', 'repose', 'serenity', 'unsounded', 'unruffled', 'common soldier', 'quiesce', 'still', 'lull', 'subdued', 'placidity', 'understood', 'tranquillise', 'quietly'}, 'noisy': {'gaudy', 'flash', 'brassy', 'garish', 'crowd', 'meretricious', 'aloud', 'loud', 'trashy', 'noisy', 'herd', 'loudly', 'tacky', 'crowded', 'forte', 'crowd together', 'flashy', 'gimcrack', 'push', 'cheap', 'tawdry', 'tatty'}, 'spacious': {'many seating', 'broad', 'wide', 'many tables', 'roomy', 'spacious', 'large space'}, 'collaborate': {'fulfill', 'assemble', 'foregather', 'encounter', 'fulfil', 'fit', 'aggroup', 'discus', 'satisfy', 'forgather', 'play', 'fill', 'receive', 'group project', 'gather', 'touch', 'discuss', 'radical', 'run into', 'get together', 'contact', 'saucer', 'come across', 'cooperate', 'match', 'sports meeting', 'talk over', 'mathematical group', 'discourse', 'chemical group', 'fitting', 'hash out', 'meet', 'adjoin', 'see', 'run across', 'converge', 'group', 'take on', 'collaborate', 'talk about', 'cope with', 'suffer', 'grouping', 'join forces', 'conform to'}, 'cozy': {'tea cosy', 'intimate', 'cosy', 'snug', 'tea cozy', 'cozy', 'informal'}, 'wi-fi': {'wi-fi', 'online meeting', 'WiFi', 'WLAN', 'internet', 'wireless local area network', 'remote meeting', 'wifi', 'cyberspace', 'wireless fidelity', 'net'}}\n"
     ]
    }
   ],
   "source": [
    "labels_with_synonyms = {\n",
    "    'quiet': get_merge_syns('quiet', 'silent', 'private', 'self study'),\n",
    "    'noisy': get_merge_syns('noisy', 'loud', 'crowded'),\n",
    "    'spacious': get_merge_syns('spacious', 'large space', 'many tables', 'many seating'),\n",
    "    'collaborate': get_merge_syns('discuss','collaborate', 'group', 'group project', 'meet'),\n",
    "    'cozy': get_merge_syns('cozy'),\n",
    "    'wi-fi': get_merge_syns('internet', 'wi-fi', 'wifi', 'remote meeting', 'online meeting'),\n",
    "}\n",
    "print(labels_with_synonyms)\n",
    "# def label_extraction(place_info):\n",
    "#     description = \"\"\n",
    "#     for r in place_info.get('reviews'):\n",
    "#         description += r['text'].lower()\n",
    "#     features = {label: 0 for label in labels_with_synonyms.keys()}\n",
    "#     print(description)\n",
    "#     for label, synonyms in labels_with_synonyms.items():\n",
    "#         count = sum(description.count(word) for word in synonyms)\n",
    "#         features[label] += count\n",
    "    \n",
    "#     return features\n",
    "\n",
    "\n",
    "\n",
    "# # Test the function\n",
    "# for i in range(len(all_places_chicago)):\n",
    "#     print(label_extraction(all_places_chicago[i]))\n",
    "\n",
    "\n",
    "\n",
    "# # {\n",
    "# #     \"quiet\": 0,\n",
    "# #     \"wifi_available\": 1,\n",
    "# #     \"ambience\": [\"cozy\"],\n",
    "# #     \"group_work\": 1\n",
    "# # }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "ff255a99-2ca7-47b1-aa29-0d6ff29ab5a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'quiet': 1, 'noisy': 0, 'spacious': 0, 'collaborate': 0, 'cozy': 0, 'wi-fi': 0}\n",
      "{'quiet': 0, 'noisy': 0, 'spacious': 0, 'collaborate': 0, 'cozy': 0, 'wi-fi': 0}\n",
      "{'quiet': 0, 'noisy': 0, 'spacious': 0, 'collaborate': 0, 'cozy': 0, 'wi-fi': 0}\n",
      "{'quiet': 1, 'noisy': 0, 'spacious': 1, 'collaborate': 1, 'cozy': 0, 'wi-fi': 0}\n",
      "{'quiet': 1, 'noisy': 0, 'spacious': 0, 'collaborate': 0, 'cozy': 0, 'wi-fi': 0}\n",
      "{'quiet': 1, 'noisy': 2, 'spacious': 0, 'collaborate': 0, 'cozy': 0, 'wi-fi': 0}\n",
      "{'quiet': 1, 'noisy': 0, 'spacious': 0, 'collaborate': 0, 'cozy': 0, 'wi-fi': 0}\n",
      "{'quiet': 0, 'noisy': 0, 'spacious': 0, 'collaborate': 0, 'cozy': 0, 'wi-fi': 0}\n",
      "{'quiet': 0, 'noisy': 0, 'spacious': 0, 'collaborate': 3, 'cozy': 0, 'wi-fi': 0}\n",
      "{'quiet': 0, 'noisy': 1, 'spacious': 0, 'collaborate': 0, 'cozy': 0, 'wi-fi': 0}\n",
      "{'quiet': 2, 'noisy': 1, 'spacious': 0, 'collaborate': 0, 'cozy': 0, 'wi-fi': 1}\n",
      "{'quiet': 0, 'noisy': 0, 'spacious': 0, 'collaborate': 1, 'cozy': 1, 'wi-fi': 0}\n",
      "{'quiet': 0, 'noisy': 1, 'spacious': 0, 'collaborate': 1, 'cozy': 0, 'wi-fi': 0}\n",
      "{'quiet': 0, 'noisy': 0, 'spacious': 0, 'collaborate': 0, 'cozy': 0, 'wi-fi': 0}\n",
      "{'quiet': 1, 'noisy': 1, 'spacious': 0, 'collaborate': 1, 'cozy': 0, 'wi-fi': 0}\n",
      "{'quiet': 0, 'noisy': 0, 'spacious': 0, 'collaborate': 0, 'cozy': 0, 'wi-fi': 0}\n",
      "{'quiet': 1, 'noisy': 0, 'spacious': 0, 'collaborate': 1, 'cozy': 0, 'wi-fi': 0}\n",
      "{'quiet': 0, 'noisy': 0, 'spacious': 0, 'collaborate': 1, 'cozy': 0, 'wi-fi': 0}\n",
      "{'quiet': 0, 'noisy': 0, 'spacious': 0, 'collaborate': 0, 'cozy': 0, 'wi-fi': 0}\n",
      "{'quiet': 0, 'noisy': 0, 'spacious': 0, 'collaborate': 0, 'cozy': 0, 'wi-fi': 0}\n",
      "{'quiet': 0, 'noisy': 0, 'spacious': 0, 'collaborate': 0, 'cozy': 0, 'wi-fi': 3}\n",
      "{'quiet': 0, 'noisy': 0, 'spacious': 0, 'collaborate': 0, 'cozy': 0, 'wi-fi': 0}\n",
      "{'quiet': 0, 'noisy': 2, 'spacious': 0, 'collaborate': 1, 'cozy': 0, 'wi-fi': 0}\n",
      "{'quiet': 0, 'noisy': 0, 'spacious': 0, 'collaborate': 0, 'cozy': 0, 'wi-fi': 0}\n",
      "{'quiet': 1, 'noisy': 0, 'spacious': 0, 'collaborate': 1, 'cozy': 0, 'wi-fi': 0}\n",
      "{'quiet': 0, 'noisy': 0, 'spacious': 0, 'collaborate': 0, 'cozy': 0, 'wi-fi': 0}\n",
      "{'quiet': 2, 'noisy': 0, 'spacious': 0, 'collaborate': 0, 'cozy': 1, 'wi-fi': 3}\n",
      "{'quiet': 2, 'noisy': 0, 'spacious': 0, 'collaborate': 0, 'cozy': 0, 'wi-fi': 0}\n",
      "{'quiet': 0, 'noisy': 0, 'spacious': 0, 'collaborate': 0, 'cozy': 0, 'wi-fi': 0}\n",
      "{'quiet': 0, 'noisy': 0, 'spacious': 0, 'collaborate': 0, 'cozy': 0, 'wi-fi': 0}\n",
      "{'quiet': 0, 'noisy': 1, 'spacious': 0, 'collaborate': 0, 'cozy': 0, 'wi-fi': 0}\n",
      "{'quiet': 3, 'noisy': 0, 'spacious': 0, 'collaborate': 0, 'cozy': 1, 'wi-fi': 0}\n",
      "{'quiet': 0, 'noisy': 0, 'spacious': 0, 'collaborate': 0, 'cozy': 0, 'wi-fi': 0}\n",
      "{'quiet': 0, 'noisy': 0, 'spacious': 0, 'collaborate': 0, 'cozy': 0, 'wi-fi': 0}\n",
      "{'quiet': 0, 'noisy': 0, 'spacious': 0, 'collaborate': 0, 'cozy': 0, 'wi-fi': 0}\n",
      "{'quiet': 0, 'noisy': 0, 'spacious': 0, 'collaborate': 0, 'cozy': 0, 'wi-fi': 0}\n",
      "{'quiet': 1, 'noisy': 0, 'spacious': 0, 'collaborate': 2, 'cozy': 0, 'wi-fi': 0}\n",
      "{'quiet': 0, 'noisy': 0, 'spacious': 0, 'collaborate': 0, 'cozy': 0, 'wi-fi': 0}\n",
      "{'quiet': 0, 'noisy': 0, 'spacious': 0, 'collaborate': 0, 'cozy': 0, 'wi-fi': 0}\n",
      "{'quiet': 0, 'noisy': 0, 'spacious': 0, 'collaborate': 1, 'cozy': 0, 'wi-fi': 0}\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def label_extraction(place_info):\n",
    "    description = \"\"\n",
    "    for r in place_info.get('reviews'):\n",
    "        description += r['text'].lower()\n",
    "    \n",
    "    features = {label: 0 for label in labels_with_synonyms.keys()}\n",
    "    \n",
    "    for label, synonyms in labels_with_synonyms.items():\n",
    "        count = 0\n",
    "        for word in synonyms:\n",
    "            # Use regular expressions to match synonyms in the description\n",
    "            pattern = r\"\\b\" + re.escape(word) + r\"\\b\"\n",
    "            matches = re.findall(pattern, description)\n",
    "            count += len(matches)\n",
    "        \n",
    "        # Exclude false positives\n",
    "        for word in synonyms:\n",
    "            negation_pattern = r\"\\bnot \" + re.escape(word) + r\"\\b\"\n",
    "            negation_matches = re.findall(negation_pattern, description)\n",
    "            count -= len(negation_matches)\n",
    "        \n",
    "        # Handle more complex patterns like \"many ... seating\"\n",
    "        if label == 'spacious':\n",
    "            complex_pattern = r\"many [\\w\\s]* seating\"\n",
    "            complex_matches = re.findall(complex_pattern, description)\n",
    "            count += len(complex_matches)\n",
    "        \n",
    "        features[label] += max(count, 0)  # Ensure count is non-negative\n",
    "    \n",
    "    return features\n",
    "\n",
    "# Test the function\n",
    "for i in range(len(all_places_chicago)):\n",
    "    print(label_extraction(all_places_chicago[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f90f6f1-1eeb-4738-b9df-a1c6a779d903",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
